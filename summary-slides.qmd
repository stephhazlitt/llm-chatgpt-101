---
title: "An Intro to ChatGPT & Large Language Models"
subtitle: "(slides made with Quarto)"
author: "ChatGPT 🤖 & Steph Hazlitt"
footer: "🔗 https://github.com/stephhazlitt/llm-chatgpt-101"
logo: "images/robot-face-emoji.png"
execute:
  echo: true
format:
  revealjs: 
    theme: default
engine: knitr
editor: source
---

## This Session

- What is ChatGPT 🤖? (hint: Large Language Model or "LLM")
- The Good, The Bad and The Ugly of ChatGPT
- Prompting and being safe with ChatGPT
- [Using an LLM on a local machine 💻]{style="color:grey;"}

## Lets Ask ChatGPT! 🤖

![](images/what-is-chatgpt.png){.absolute top="75"}

## Lets Ask ChatGPT! 🤖

A more detailed "prompt":

![](images/ask-chatgpt-2.png){.absolute top="75"}

## Answer 🤖

![](images/ask-chatgpt-3.png){.absolute top="75"}


## Answer 🤖

![](images/ask-chatgpt-4.png){.absolute top="60"}

## Large Language Model (LLM)

![](images/llm.png){.absolute top="60"}

## Large Language Model (LLM)

![](images/llm-pl.png){.absolute top="60"}

## ChatGPT 🤖

-   Generative: create something "new" (text)
-   Pre-training: Large Language Model (LLM) trained on a lot of data
-   Transformer: describes the design of this AI model
-   "Chat": trained on text & "conversational" data

> Developed by OpenAI, accessable via an easy to use browser-based user interface

## Who is OpenAI? 🪟

OpenAI is an AI research and deployment company.

> We are governed by a nonprofit and our unique capped-profit model drives our commitment to safety. This means that as AI becomes more powerful, we can redistribute profits from our work to maximize the social and economic benefits of AI technology.

<https://openai.com/about>

<br> [Note: It is reported that Microsoft’s investments in OpenAI give it a 49% stake in the company (billions of $)]{style="color:orange;"}


## ChatGPT 👩‍💻🧑‍💻

- LLM model trained on ~45 terabytes of data, including all of Wikipedia, books, and webpages (up until Sept 2021)
-  \>100 million users in ~2 months, fastest-growing consumer software application _ever_
- ‘research preview’ is "free"---which allows OpenAI to assess the system’s strengths + weaknesses and gather feedback from early adopters

::: notes
Facebook took almost 5 years; Canva took 9 years; and Instagram needed 2.5 years to reach 100 million users. This was a feat achieved by ChatGPT in a mere 60 days or so
:::

## ChatGPT ☁️💸

- training each model costs estimated to be ~$5 million dollars 🤯
- ChatGPT sits on Microsoft’s Azure Cloud infrastructure ($3/h single A100GPU super computer cluster)
- running costs estimated between $100,000 and $700,000 per day ($3-$21 million per month)
- OpenAI monetizing with ChatGPT Plus subscription (GPT-4 w/ 5x training parameters) for $20 per month fee

## What is ChatGPT _GOOD_ at? 🤖

![](images/chatgpt-good-for.png){.absolute top="75" width="700"}

## Facts Like Geography 🇨🇦

![](images/canada.png){.absolute top="75" height="600"}

## Generate Machine Readable Data ⊹

![](images/table.png){.absolute top="75"}

## Content Drafting ✍️

![](images/email.png){.absolute top="75"}

## Creative Writing: Open Data on a Pirate Ship ⚓️

![](images/pirate-voice.png){.absolute top="175"}


## Code 💻 

::: columns
::: {.column width="70%"}
![](images/code.png){.absolute top="75" width="800"}
:::

::: {.column width="30%"}

::: {style="font-size: 40%;"}
<br>
<https://allisonhorst.github.io/palmerpenguins/>
:::
:::
:::

## And the Code Works 📊

![](images/code-works.png)

## What is ChatGPT _NOT GOOD_ at? 🤖

![](images/chatgpt-not-good-for.png)

## What is ChatGPT _NOT GOOD_ at? 🤖

![](images/chatgpt-not-good-for2.png){.absolute top="75"}



## Many Additional Concerns about ChatGPT & LLMs 🤖

- 

## Prompting Tips

- simple + short gets you started, but specificity gets much better results, e.g., style, tone, persona, length


![](images/prompt-engineering.png){.absolute top="300"}

## Prompt Engineering



- request the return format you want (e.g., csv/table, haiku, json file, slides)

## Add the Context ChatGPT Does Not Know



## Few-Shot Prompting

- Provide examples (as opposed to "zero-shot" or providing instruction without an example)


::: notes
All our prompts so far use what is called zero-shot prompting, which means that we are providing instruction without any example. But in many cases, it is extremely helpful to provide examples to the model to guide its response. This is called few-shot prompting.
:::

## Chain of Thought Prompting

- Provide example in a prompt that show a response that includes a reasoning step

## Ask for Steps

- Add instructions for the model to generate intermediate steps before generating the final output.

